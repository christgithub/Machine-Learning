{"cells":[{"cell_type":"markdown","metadata":{"id":"rWkkIl4rxxPy"},"source":["## Calculating cost with gradient descent and learning rate\n","- Change the iteration and learning rate vaules and see the impact on cost.\n","- Low iteration values with high learning rate (i.e. big steps) may lead to miss the global minimum\n","- Goal is to reach minimum cost with minimum iteration"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_u6rMJyxxP1","executionInfo":{"status":"ok","timestamp":1737966137630,"user_tz":0,"elapsed":140,"user":{"displayName":"Chris L","userId":"09170712043726965145"}},"outputId":"25c1f2c8-f204-4cf7-c90f-09d539411b95"},"outputs":[{"output_type":"stream","name":"stdout","text":["m 4.6499999999999995, b 1.3499999999999999, cost 89.0 iteration 0\n","m 1.0200000000000005, b 0.405, cost 53.734999999999985 iteration 1\n","m 3.8047499999999994, b 1.2352499999999997, cost 32.557024999999975 iteration 2\n","m 1.6210499999999999, b 0.687825, cost 19.833095374999985 iteration 3\n","m 3.28679625, b 1.20517875, cost 12.182979655625003 iteration 4\n","m 1.9712519999999996, b 0.8953436249999998, cost 7.578258275084384 iteration 5\n","m 2.9657815687500007, b 1.22397868125, cost 4.801697348183148 iteration 6\n","m 2.1714515737499998, b 1.0557801731249996, cost 3.122834216428902 iteration 7\n","m 2.7634553991562507, b 1.27025993896875, cost 2.1033055045666997 iteration 8\n","m 2.2821370180125, b 1.1861660185031246, cost 1.4800299578584992 iteration 9\n","m 2.632836229965469, b 1.331279457622031, cost 1.0951097144400397 iteration 10\n","m 2.339580694592531, b 1.2968112354942654, cost 0.8537659806537722 iteration 11\n","m 2.5457074925424354, b 1.3994782376034867, cost 0.6990973550396624 iteration 12\n","m 2.365524922925848, b 1.3939881303188677, cost 0.5969329471893107 iteration 13\n","m 2.4851141414547087, b 1.470403695454406, cost 0.5267430983369474 iteration 14\n","m 2.3729941450999568, b 1.4815417774816262, cost 0.47618509920068197 iteration 15\n","m 2.4408600058182963, b 1.5414631455644017, cost 0.4378301691315383 iteration 16\n","m 2.369782580714127, b 1.561856671111508, cost 0.40719935098201554 iteration 17\n","m 2.406805820535639, b 1.6111760091234248, cost 0.381584851862919 iteration 18\n","m 2.3605470125462937, b 1.6364369885138736, cost 0.35934271034400056 iteration 19\n","m 2.379247797013666, b 1.6787252845909604, cost 0.33946829585004107 iteration 20\n","m 2.348062553875185, b 1.7062549832461666, cost 0.3213415301037248 iteration 21\n","m 2.355944597520355, b 1.7436885865154084, cost 0.3045739563188538 iteration 22\n","m 2.3339761476798357, b 1.7719602296539374, cost 0.2889169265968476 iteration 23\n","m 2.3355334006638353, b 1.8058769287499208, cost 0.2742064667744592 iteration 24\n","m 2.319258671631043, b 1.8340053591387069, cost 0.2603301524170435 iteration 25\n","m 2.317179451827404, b 1.8652381530339315, cost 0.2472071950233069 iteration 26\n","m 2.304476187446918, b 1.89272167675651, cost 0.23477645715459988 iteration 27\n","m 2.3003657236190738, b 1.9217991408919204, cost 0.22298922724646936 iteration 28\n","m 2.2899526662462377, b 1.9483646941295492, cost 0.21180485224247692 iteration 29\n","m 2.2847666545816483, b 1.9756312901993098, cost 0.20118808671467053 iteration 30\n","m 2.2758675939322393, b 2.001141602107672, cost 0.19110747350822113 iteration 31\n","m 2.270172342995592, b 2.0268299445220133, cost 0.1815343448082131 iteration 32\n","m 2.262314502017959, b 2.0512278984956946, cost 0.17244219686620618 iteration 33\n","m 2.256443019365264, b 2.075502187813259, cost 0.16380629024331805 iteration 34\n","m 2.249336052896612, b 2.0987775009269014, cost 0.15560338660848394 iteration 35\n","m 2.2434816902000962, b 2.121759651984391, cost 0.1478115686472027 iteration 36\n","m 2.2369450579769614, b 2.143928943596689, cost 0.14041011095166264 iteration 37\n","m 2.231217687696465, b 2.165714325967553, cost 0.13337938255695578 iteration 38\n","m 2.225137056311899, b 2.1868092176090106, cost 0.12670076946805975 iteration 39\n","m 2.219596765473211, b 2.2074761596273045, cost 0.1203566101334641 iteration 40\n","m 2.2138978306101254, b 2.227536191220264, cost 0.11433013959083849 iteration 41\n","m 2.2085751240543, b 2.247151738762668, cost 0.10860543967447184 iteration 42\n","m 2.2032078869215046, b 2.266220172123833, cost 0.10316739367516335 iteration 43\n","m 2.1981157960452973, b 2.284843597190581, cost 0.0980016444460625 iteration 44\n","m 2.193045113834795, b 2.30296494939161, cost 0.0930945553117121 iteration 45\n","m 2.188186448781159, b 2.3206499057572105, cost 0.08843317335778689 iteration 46\n","m 2.1833863507015017, b 2.3378685179421073, cost 0.08400519481301127 iteration 47\n","m 2.178758038970076, b 2.354664382435115, cost 0.07979893231689464 iteration 48\n","m 2.174208302573649, b 2.371023607533314, cost 0.07580328391789995 iteration 49\n"]}],"source":["# code credit:codebasics https://codebasics.io/coming-soon\n","\n","import numpy as np\n","\n","def gradient_descent(x,y):\n","    m_curr = b_curr = 0\n","    iterations = 50       #change value\n","    n = len(x)\n","    learning_rate = 0.075   #change value\n","\n","    for i in range(iterations):\n","        y_predicted = m_curr * x + b_curr  #y = mx + b\n","        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n","        md = -(2/n)*sum(x*(y-y_predicted))\n","        bd = -(2/n)*sum(y-y_predicted)\n","        m_curr = m_curr - learning_rate * md\n","        b_curr = b_curr - learning_rate * bd\n","        print (\"m {}, b {}, cost {} iteration {}\".format(m_curr,b_curr,cost, i))\n","\n","x = np.array([1,2,3,4,5])\n","y = np.array([5,7,9,11,13])\n","\n","gradient_descent(x,y)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"_joXYt0KxxP2","executionInfo":{"status":"ok","timestamp":1737964353131,"user_tz":0,"elapsed":5,"user":{"displayName":"Chris L","userId":"09170712043726965145"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}